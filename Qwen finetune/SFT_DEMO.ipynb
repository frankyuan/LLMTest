{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba40a847-a64e-4e6b-a44d-d8cef69ff9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T01:43:32.660497Z",
     "iopub.status.busy": "2024-02-17T01:43:32.660193Z",
     "iopub.status.idle": "2024-02-17T01:43:36.000692Z",
     "shell.execute_reply": "2024-02-17T01:43:36.000174Z",
     "shell.execute_reply.started": "2024-02-17T01:43:32.660467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd77a439-a151-491d-b9f0-163e0941bf24",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T01:55:23.543943Z",
     "iopub.status.busy": "2024-02-17T01:55:23.543609Z",
     "iopub.status.idle": "2024-02-17T01:55:24.863852Z",
     "shell.execute_reply": "2024-02-17T01:55:24.863215Z",
     "shell.execute_reply.started": "2024-02-17T01:55:23.543925Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 09:55:23,843 - modelscope - WARNING - Using the master branch is fragile, please use it with caution!\n",
      "2024-02-17 09:55:23,844 - modelscope - INFO - Use user-specified model revision: master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/.cache/modelscope/qwen/Qwen-1_8B-Chat-Int4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "QWenLMHeadModel.__init__() got an unexpected keyword argument 'disable_exllama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Loading local checkpoints\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# trust_remote_code is still set as True since we still load codes from local dir instead of transformers\u001b[39;00m\n\u001b[1;32m     13\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_exllama\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3462\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3456\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   3457\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3458\u001b[0m )\n\u001b[1;32m   3460\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3461\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 3462\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3465\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "\u001b[0;31mTypeError\u001b[0m: QWenLMHeadModel.__init__() got an unexpected keyword argument 'disable_exllama'"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Downloading model checkpoint to a local dir model_dir\n",
    "# model_dir = snapshot_download('qwen/Qwen-7B')\n",
    "# model_dir = snapshot_download('qwen/Qwen-7B-Chat')\n",
    "# model_dir = snapshot_download('qwen/Qwen-14B')\n",
    "model_dir = snapshot_download('qwen/Qwen-1_8B-Chat-Int4', revision='master')\n",
    "print(model_dir)\n",
    "\n",
    "# Loading local checkpoints\n",
    "# trust_remote_code is still set as True since we still load codes from local dir instead of transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48d61bb7-afa6-4dab-bc33-a68bc4cf81e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T02:24:21.761531Z",
     "iopub.status.busy": "2024-02-17T02:24:21.761209Z",
     "iopub.status.idle": "2024-02-17T02:24:21.766057Z",
     "shell.execute_reply": "2024-02-17T02:24:21.765578Z",
     "shell.execute_reply.started": "2024-02-17T02:24:21.761510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('city.txt','r',encoding='utf-8') as fp:\n",
    "    city_list=fp.readlines()\n",
    "    city_list=[line.strip().split(' ')[1] for line in city_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f22a45-8efc-46cb-beb3-76b17651a8f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T02:24:23.328487Z",
     "iopub.status.busy": "2024-02-17T02:24:23.328123Z",
     "iopub.status.idle": "2024-02-17T02:24:23.331292Z",
     "shell.execute_reply": "2024-02-17T02:24:23.330858Z",
     "shell.execute_reply.started": "2024-02-17T02:24:23.328466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q='青岛4月6日下雨么?'\n",
    "\n",
    "prompt_template='''\n",
    "给定一句话：“%s”，请你按步骤要求工作。\n",
    "\n",
    "步骤1：识别这句话中的城市和日期共2个信息\n",
    "步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\n",
    "\n",
    "请问，这个JSON字符串是：\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff4b6b12-6124-4679-8350-71db4639dceb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T02:35:04.068934Z",
     "iopub.status.busy": "2024-02-17T02:35:04.068609Z",
     "iopub.status.idle": "2024-02-17T02:35:04.096116Z",
     "shell.execute_reply": "2024-02-17T02:35:04.095652Z",
     "shell.execute_reply.started": "2024-02-17T02:35:04.068916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import time \n",
    "\n",
    "Q_arr=[]\n",
    "A_arr=[]\n",
    "\n",
    "Q_list=[\n",
    "    ('{city}{year}年{month}月{day}日的天气','%Y-%m-%d'),\n",
    "    ('{city}{year}年{month}月{day}号的天气','%Y-%m-%d'),\n",
    "    ('{city}{month}月{day}日的天气','%m-%d'),\n",
    "    ('{city}{month}月{day}号的天气','%m-%d'),\n",
    "\n",
    "    ('{year}年{month}月{day}日{city}的天气','%Y-%m-%d'),\n",
    "    ('{year}年{month}月{day}号{city}的天气','%Y-%m-%d'),\n",
    "    ('{month}月{day}日{city}的天气','%m-%d'),\n",
    "    ('{month}月{day}号{city}的天气','%m-%d'),\n",
    "\n",
    "    ('你们{year}年{month}月{day}日去{city}玩吗？','%Y-%m-%d'),\n",
    "    ('你们{year}年{month}月{day}号去{city}玩么？','%Y-%m-%d'),\n",
    "    ('你们{month}月{day}日去{city}玩吗？','%m-%d'),\n",
    "    ('你们{month}月{day}号去{city}玩吗？','%m-%d'),\n",
    "]\n",
    "\n",
    "# 生成一批\"1月2号\"、\"1月2日\"、\"2023年1月2号\", \"2023年1月2日\", \"2023-02-02\", \"03-02\"之类的话术, 教会它做日期转换\n",
    "for i in range(1000):\n",
    "    Q=Q_list[random.randint(0,len(Q_list)-1)]\n",
    "    city=city_list[random.randint(0,len(city_list)-1)]\n",
    "    year=random.randint(1990,2025)\n",
    "    month=random.randint(1,12)\n",
    "    day=random.randint(1,28)\n",
    "    time_str='{}-{}-{}'.format(year,month,day)\n",
    "    date_field=time.strftime(Q[1],time.strptime(time_str,'%Y-%m-%d'))\n",
    "    Q=Q[0].format(city=city,year=year,month=month,day=day) # 问题\n",
    "    A=json.dumps({'city':city,'date':date_field},ensure_ascii=False)  # 回答\n",
    "\n",
    "    Q_arr.append(prompt_template%(Q,))\n",
    "    A_arr.append(A)\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(Q_arr)):\n",
    "    example = {\n",
    "        'id': 'identity_{}'.format(i),\n",
    "        'conversations': [\n",
    "            {\n",
    "                'from': 'user',\n",
    "                'value': Q_arr[i],\n",
    "            },\n",
    "            {\n",
    "                'from': 'assistant',\n",
    "                'value': A_arr[i]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    train_data.append(example)\n",
    "\n",
    "with open('train.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write(json.dumps(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28ea20-84e3-4654-8ec5-a3fb4ece7bc8",
   "metadata": {},
   "source": [
    "微调模型，生成到output_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55a74d88-719d-4deb-a704-18b4d1603b26",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T02:35:19.513591Z",
     "iopub.status.busy": "2024-02-17T02:35:19.513263Z",
     "iopub.status.idle": "2024-02-17T02:55:46.029730Z",
     "shell.execute_reply": "2024-02-17T02:55:46.028988Z",
     "shell.execute_reply.started": "2024-02-17T02:35:19.513571Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-17 10:35:21,335] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2024-02-17 10:35:22.749612: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-17 10:35:22.751932: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-17 10:35:22.781846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-17 10:35:22.781864: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-17 10:35:22.781885: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-17 10:35:22.787624: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-17 10:35:22.787859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-17 10:35:23.481717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "trainable params: 53,673,984 || all params: 676,104,192 || trainable%: 7.938714866006925\n",
      "Loading data...\n",
      "Formatting inputs...Skip in lazy mode\n",
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "  0%|                                                   | 0/310 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 0.4319, 'learning_rate': 7.5e-05, 'epoch': 0.02}                       \n",
      "{'loss': 0.3947, 'learning_rate': 0.00015, 'epoch': 0.03}                       \n",
      "{'loss': 0.2956, 'learning_rate': 0.000225, 'epoch': 0.05}                      \n",
      "{'loss': 0.1695, 'learning_rate': 0.0003, 'epoch': 0.06}                        \n",
      "{'loss': 0.0493, 'learning_rate': 0.00029999209477307595, 'epoch': 0.08}        \n",
      "{'loss': 0.0351, 'learning_rate': 0.0002999683799255387, 'epoch': 0.1}          \n",
      "{'loss': 0.0483, 'learning_rate': 0.0002999288579570049, 'epoch': 0.11}         \n",
      "{'loss': 0.0414, 'learning_rate': 0.00029987353303320956, 'epoch': 0.13}        \n",
      "{'loss': 0.034, 'learning_rate': 0.00029980241098556714, 'epoch': 0.14}         \n",
      "{'loss': 0.0343, 'learning_rate': 0.0002997154993105566, 'epoch': 0.16}         \n",
      "{'loss': 0.0373, 'learning_rate': 0.00029961280716893146, 'epoch': 0.18}        \n",
      "{'loss': 0.0159, 'learning_rate': 0.00029949434538475414, 'epoch': 0.19}        \n",
      "{'loss': 0.0297, 'learning_rate': 0.00029936012644425517, 'epoch': 0.21}        \n",
      "{'loss': 0.0079, 'learning_rate': 0.0002992101644945169, 'epoch': 0.22}         \n",
      "{'loss': 0.009, 'learning_rate': 0.0002990444753419826, 'epoch': 0.24}          \n",
      "{'loss': 0.0015, 'learning_rate': 0.0002988630764507904, 'epoch': 0.26}         \n",
      "{'loss': 0.0014, 'learning_rate': 0.000298665986940932, 'epoch': 0.27}          \n",
      "{'loss': 0.003, 'learning_rate': 0.0002984532275862383, 'epoch': 0.29}          \n",
      "{'loss': 0.0021, 'learning_rate': 0.00029822482081218887, 'epoch': 0.3}         \n",
      "{'loss': 0.0039, 'learning_rate': 0.0002979807906935489, 'epoch': 0.32}         \n",
      "{'loss': 0.0035, 'learning_rate': 0.0002977211629518312, 'epoch': 0.34}         \n",
      "{'loss': 0.0062, 'learning_rate': 0.00029744596495258525, 'epoch': 0.35}        \n",
      "{'loss': 0.0011, 'learning_rate': 0.00029715522570251284, 'epoch': 0.37}        \n",
      "{'loss': 0.001, 'learning_rate': 0.0002968489758464107, 'epoch': 0.38}          \n",
      "{'loss': 0.0005, 'learning_rate': 0.00029652724766394007, 'epoch': 0.4}         \n",
      "{'loss': 0.0007, 'learning_rate': 0.00029619007506622504, 'epoch': 0.42}        \n",
      "{'loss': 0.022, 'learning_rate': 0.0002958374935922774, 'epoch': 0.43}          \n",
      "{'loss': 0.0051, 'learning_rate': 0.0002954695404052514, 'epoch': 0.45}         \n",
      "{'loss': 0.0003, 'learning_rate': 0.0002950862542885262, 'epoch': 0.46}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00029468767564161825, 'epoch': 0.48}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.00029427384647592284, 'epoch': 0.5}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00029384481041028616, 'epoch': 0.51}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.00029340061266640765, 'epoch': 0.53}        \n",
      "{'loss': 0.0003, 'learning_rate': 0.0002929413000640735, 'epoch': 0.54}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002924669210162217, 'epoch': 0.56}         \n",
      "{'loss': 0.0006, 'learning_rate': 0.00029197752552383914, 'epoch': 0.58}        \n",
      "{'loss': 0.0004, 'learning_rate': 0.00029147316517069157, 'epoch': 0.59}        \n",
      "{'loss': 0.0004, 'learning_rate': 0.0002909538931178862, 'epoch': 0.61}         \n",
      "{'loss': 0.0003, 'learning_rate': 0.00029041976409826853, 'epoch': 0.62}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002898708344106533, 'epoch': 0.64}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028930716191389054, 'epoch': 0.66}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002887288060207667, 'epoch': 0.67}         \n",
      "{'loss': 0.0004, 'learning_rate': 0.000288135827691743, 'epoch': 0.69}          \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028752828942852943, 'epoch': 0.7}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028690625526749705, 'epoch': 0.72}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002862697907729285, 'epoch': 0.74}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028561896303010734, 'epoch': 0.75}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002849538406382468, 'epoch': 0.77}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028427449370325937, 'epoch': 0.78}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002835809938303674, 'epoch': 0.8}          \n",
      "{'loss': 0.0005, 'learning_rate': 0.00028287341411655593, 'epoch': 0.82}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.00028215182914286766, 'epoch': 0.83}        \n",
      "{'loss': 0.0003, 'learning_rate': 0.000281416314966542, 'epoch': 0.85}          \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002806669491129986, 'epoch': 0.86}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002799038105676658, 'epoch': 0.88}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.0002791269797676551, 'epoch': 0.9}          \n",
      "{'loss': 0.0002, 'learning_rate': 0.00027833653859328343, 'epoch': 0.91}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002775325703594421, 'epoch': 0.93}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002767151598068155, 'epoch': 0.94}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.000275884393092949, 'epoch': 0.96}          \n",
      "{'loss': 0.0003, 'learning_rate': 0.0002750403577831679, 'epoch': 0.98}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00027418314284134764, 'epoch': 0.99}        \n",
      "{'loss': 0.0005, 'learning_rate': 0.00027331283862053673, 'epoch': 1.01}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.00027242953685343327, 'epoch': 1.02}        \n",
      "{'loss': 0.0002, 'learning_rate': 0.000271533330642716, 'epoch': 1.04}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00027062431445123124, 'epoch': 1.06}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026970258409203594, 'epoch': 1.07}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002687682367182987, 'epoch': 1.09}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002678213708130598, 'epoch': 1.1}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026686208617885055, 'epoch': 1.12}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002658904839271738, 'epoch': 1.14}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026490666646784665, 'epoch': 1.15}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026391073749820607, 'epoch': 1.17}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026290280199217864, 'epoch': 1.18}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002618829661892165, 'epoch': 1.2}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00026085133758309883, 'epoch': 1.22}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00025980802491060216, 'epoch': 1.23}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00025875313814003887, 'epoch': 1.25}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002576867884596663, 'epoch': 1.26}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00025660908826596705, 'epoch': 1.28}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00025552015115180247, 'epoch': 1.3}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.000254420091894439, 'epoch': 1.31}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002533090264434508, 'epoch': 1.33}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002521870719084981, 'epoch': 1.34}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00025105434654698356, 'epoch': 1.36}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002499109697515875, 'epoch': 1.38}         \n",
      "{'loss': 0.0002, 'learning_rate': 0.00024875706203768364, 'epoch': 1.39}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002475927450306363, 'epoch': 1.41}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002464181414529809, 'epoch': 1.42}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002452333751114884, 'epoch': 1.44}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.000244038570884116, 'epoch': 1.46}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00024283385470684417, 'epoch': 1.47}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00024161935356040317, 'epoch': 1.49}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00024039519545688846, 'epoch': 1.5}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023916150942626798, 'epoch': 1.52}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023791842550278217, 'epoch': 1.54}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023666607471123767, 'epoch': 1.55}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023540458905319702, 'epoch': 1.57}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023413410149306546, 'epoch': 1.58}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023285474594407585, 'epoch': 1.6}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.000231566657254174, 'epoch': 1.62}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00023026997119180502, 'epoch': 1.63}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00022896482443160335, 'epoch': 1.65}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00022765135453998636, 'epoch': 1.66}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00022632969996065473, 'epoch': 1.68}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.000225, 'epoch': 1.7}                       \n",
      "{'loss': 0.0001, 'learning_rate': 0.00022366239481242124, 'epoch': 1.71}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002223170253855523, 'epoch': 1.73}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002209640335254015, 'epoch': 1.74}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002196035618414045, 'epoch': 1.76}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00021823575373139316, 'epoch': 1.78}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00021686075336648075, 'epoch': 1.79}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00021547870567586595, 'epoch': 1.81}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00021408975633155713, 'epoch': 1.82}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002126940517330175, 'epoch': 1.84}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002112917389917347, 'epoch': 1.86}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002098829659157146, 'epoch': 1.87}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00020846788099390188, 'epoch': 1.89}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00020704663338052886, 'epoch': 1.9}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002056193728793941, 'epoch': 1.92}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00020418624992807295, 'epoch': 1.94}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0002027474155820605, 'epoch': 1.95}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00020130302149885031, 'epoch': 1.97}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00019985321992194892, 'epoch': 1.98}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00019839816366482921, 'epoch': 2.0}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00019693800609482315, 'epoch': 2.02}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001954729011169565, 'epoch': 2.03}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001940030031577269, 'epoch': 2.05}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00019252846714882662, 'epoch': 2.06}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00019104944851081244, 'epoch': 2.08}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018956610313672375, 'epoch': 2.1}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018807858737565115, 'epoch': 2.11}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018658705801625656, 'epoch': 2.13}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001850916722702473, 'epoch': 2.14}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018359258775580545, 'epoch': 2.16}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018208996248097458, 'epoch': 2.18}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00018058395482700517, 'epoch': 2.19}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001790747235316605, 'epoch': 2.21}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00017756242767248557, 'epoch': 2.22}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00017604722665003956, 'epoch': 2.24}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00017452928017109472, 'epoch': 2.26}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00017300874823180282, 'epoch': 2.27}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00017148579110083073, 'epoch': 2.29}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016996056930246805, 'epoch': 2.3}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016843324359970712, 'epoch': 2.32}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016690397497729818, 'epoch': 2.34}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016537292462478104, 'epoch': 2.35}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001638402539194953, 'epoch': 2.37}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016230612440957065, 'epoch': 2.38}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00016077069779689914, 'epoch': 2.4}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015923413592009144, 'epoch': 2.42}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015769660073741842, 'epoch': 2.43}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001561582543097405, 'epoch': 2.45}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015461925878342556, 'epoch': 2.46}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015307977637325854, 'epoch': 2.48}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015153996934534348, 'epoch': 2.5}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00015, 'epoch': 2.51}                       \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014846003065465652, 'epoch': 2.53}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014692022362674143, 'epoch': 2.54}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014538074121657447, 'epoch': 2.56}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014384174569025953, 'epoch': 2.58}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014230339926258153, 'epoch': 2.59}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00014076586407990856, 'epoch': 2.61}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013922930220310083, 'epoch': 2.62}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013769387559042936, 'epoch': 2.64}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001361597460805047, 'epoch': 2.66}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013462707537521894, 'epoch': 2.67}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013309602502270185, 'epoch': 2.69}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013156675640029289, 'epoch': 2.7}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00013003943069753198, 'epoch': 2.72}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001285142088991693, 'epoch': 2.74}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00012699125176819716, 'epoch': 2.75}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00012547071982890523, 'epoch': 2.77}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00012395277334996044, 'epoch': 2.78}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001224375723275144, 'epoch': 2.8}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.00012092527646833949, 'epoch': 2.82}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011941604517299484, 'epoch': 2.83}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011791003751902542, 'epoch': 2.85}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011640741224419455, 'epoch': 2.86}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011490832772975275, 'epoch': 2.88}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011341294198374341, 'epoch': 2.9}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011192141262434882, 'epoch': 2.91}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00011043389686327618, 'epoch': 2.93}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010895055148918756, 'epoch': 2.94}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010747153285117337, 'epoch': 2.96}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010599699684227311, 'epoch': 2.98}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010452709888304347, 'epoch': 2.99}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010306199390517686, 'epoch': 3.01}        \n",
      "{'loss': 0.0001, 'learning_rate': 0.0001016018363351708, 'epoch': 3.02}         \n",
      "{'loss': 0.0001, 'learning_rate': 0.00010014678007805106, 'epoch': 3.04}        \n",
      "{'loss': 0.0001, 'learning_rate': 9.869697850114969e-05, 'epoch': 3.06}         \n",
      "{'loss': 0.0001, 'learning_rate': 9.725258441793947e-05, 'epoch': 3.07}         \n",
      "{'loss': 0.0001, 'learning_rate': 9.581375007192705e-05, 'epoch': 3.09}         \n",
      "{'loss': 0.0001, 'learning_rate': 9.438062712060588e-05, 'epoch': 3.1}          \n",
      "{'loss': 0.0001, 'learning_rate': 9.295336661947115e-05, 'epoch': 3.12}         \n",
      "{'loss': 0.0001, 'learning_rate': 9.15321190060981e-05, 'epoch': 3.14}          \n",
      "{'loss': 0.0001, 'learning_rate': 9.011703408428538e-05, 'epoch': 3.15}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.870826100826527e-05, 'epoch': 3.17}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.730594826698253e-05, 'epoch': 3.18}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.59102436684429e-05, 'epoch': 3.2}           \n",
      "{'loss': 0.0001, 'learning_rate': 8.452129432413395e-05, 'epoch': 3.22}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.313924663351926e-05, 'epoch': 3.23}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.176424626860684e-05, 'epoch': 3.25}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.039643815859551e-05, 'epoch': 3.26}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.90359664745985e-05, 'epoch': 3.28}          \n",
      "{'loss': 0.0001, 'learning_rate': 7.768297461444765e-05, 'epoch': 3.3}          \n",
      "{'loss': 0.0001, 'learning_rate': 7.633760518757881e-05, 'epoch': 3.31}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.500000000000002e-05, 'epoch': 3.33}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.367030003934528e-05, 'epoch': 3.34}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.234864546001362e-05, 'epoch': 3.36}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.10351755683966e-05, 'epoch': 3.38}          \n",
      "{'loss': 0.0001, 'learning_rate': 6.973002880819495e-05, 'epoch': 3.39}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.843334274582601e-05, 'epoch': 3.41}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.714525405592412e-05, 'epoch': 3.42}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.586589850693455e-05, 'epoch': 3.44}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.4595410946803e-05, 'epoch': 3.46}           \n",
      "{'loss': 0.0001, 'learning_rate': 6.333392528876233e-05, 'epoch': 3.47}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.208157449721784e-05, 'epoch': 3.49}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.0838490573731996e-05, 'epoch': 3.5}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.960480454311155e-05, 'epoch': 3.52}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.8380646439596825e-05, 'epoch': 3.54}        \n",
      "{'loss': 0.0001, 'learning_rate': 5.716614529315581e-05, 'epoch': 3.55}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.596142911588406e-05, 'epoch': 3.57}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.4766624888511586e-05, 'epoch': 3.58}        \n",
      "{'loss': 0.0001, 'learning_rate': 5.358185854701909e-05, 'epoch': 3.6}          \n",
      "{'loss': 0.0001, 'learning_rate': 5.240725496936372e-05, 'epoch': 3.62}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.124293796231638e-05, 'epoch': 3.63}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.008903024841248e-05, 'epoch': 3.65}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.8945653453016415e-05, 'epoch': 3.66}        \n",
      "{'loss': 0.0001, 'learning_rate': 4.781292809150185e-05, 'epoch': 3.68}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.669097355654921e-05, 'epoch': 3.7}          \n",
      "{'loss': 0.0001, 'learning_rate': 4.5579908105561016e-05, 'epoch': 3.71}        \n",
      "{'loss': 0.0001, 'learning_rate': 4.447984884819752e-05, 'epoch': 3.73}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.339091173403293e-05, 'epoch': 3.74}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.231321154033372e-05, 'epoch': 3.76}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.12468618599611e-05, 'epoch': 3.78}          \n",
      "{'loss': 0.0001, 'learning_rate': 4.019197508939783e-05, 'epoch': 3.79}         \n",
      "{'loss': 0.0, 'learning_rate': 3.914866241690115e-05, 'epoch': 3.81}            \n",
      "{'loss': 0.0001, 'learning_rate': 3.811703381078351e-05, 'epoch': 3.82}         \n",
      "{'loss': 0.0001, 'learning_rate': 3.709719800782133e-05, 'epoch': 3.84}         \n",
      "{'loss': 0.0001, 'learning_rate': 3.6089262501793915e-05, 'epoch': 3.86}        \n",
      "{'loss': 0.0001, 'learning_rate': 3.509333353215331e-05, 'epoch': 3.87}         \n",
      "{'loss': 0.0, 'learning_rate': 3.410951607282617e-05, 'epoch': 3.89}            \n",
      "{'loss': 0.0, 'learning_rate': 3.3137913821149425e-05, 'epoch': 3.9}            \n",
      "{'loss': 0.0001, 'learning_rate': 3.21786291869402e-05, 'epoch': 3.92}          \n",
      "{'loss': 0.0001, 'learning_rate': 3.1231763281701305e-05, 'epoch': 3.94}        \n",
      "{'loss': 0.0001, 'learning_rate': 3.0297415907964073e-05, 'epoch': 3.95}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.937568554876873e-05, 'epoch': 3.97}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.8466669357283967e-05, 'epoch': 3.98}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.7570463146566758e-05, 'epoch': 4.0}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.6687161379463263e-05, 'epoch': 4.02}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.5816857158652316e-05, 'epoch': 4.03}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.495964221683209e-05, 'epoch': 4.05}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.4115606907051005e-05, 'epoch': 4.06}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.3284840193184516e-05, 'epoch': 4.08}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.24674296405579e-05, 'epoch': 4.1}           \n",
      "{'loss': 0.0001, 'learning_rate': 2.166346140671653e-05, 'epoch': 4.11}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.087302023234485e-05, 'epoch': 4.13}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.009618943233419e-05, 'epoch': 4.14}         \n",
      "{'loss': 0.0001, 'learning_rate': 1.9333050887001335e-05, 'epoch': 4.16}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.858368503345798e-05, 'epoch': 4.18}         \n",
      "{'loss': 0.0, 'learning_rate': 1.7848170857132325e-05, 'epoch': 4.19}           \n",
      "{'loss': 0.0001, 'learning_rate': 1.712658588344401e-05, 'epoch': 4.21}         \n",
      "{'loss': 0.0001, 'learning_rate': 1.641900616963257e-05, 'epoch': 4.22}         \n",
      "{'loss': 0.0, 'learning_rate': 1.5725506296740663e-05, 'epoch': 4.24}           \n",
      "{'loss': 0.0001, 'learning_rate': 1.5046159361753224e-05, 'epoch': 4.26}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.4381036969892618e-05, 'epoch': 4.27}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.3730209227071436e-05, 'epoch': 4.29}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.309374473250296e-05, 'epoch': 4.3}          \n",
      "{'loss': 0.0001, 'learning_rate': 1.2471710571470578e-05, 'epoch': 4.32}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.1864172308256947e-05, 'epoch': 4.34}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.1271193979233256e-05, 'epoch': 4.35}        \n",
      "{'loss': 0.0, 'learning_rate': 1.0692838086109462e-05, 'epoch': 4.37}           \n",
      "{'loss': 0.0001, 'learning_rate': 1.0129165589346643e-05, 'epoch': 4.38}        \n",
      "{'loss': 0.0001, 'learning_rate': 9.580235901731426e-06, 'epoch': 4.4}          \n",
      "{'loss': 0.0001, 'learning_rate': 9.046106882113751e-06, 'epoch': 4.42}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.526834829308382e-06, 'epoch': 4.43}         \n",
      "{'loss': 0.0001, 'learning_rate': 8.022474476160824e-06, 'epoch': 4.45}         \n",
      "{'loss': 0.0, 'learning_rate': 7.53307898377834e-06, 'epoch': 4.46}             \n",
      "{'loss': 0.0001, 'learning_rate': 7.058699935926526e-06, 'epoch': 4.48}         \n",
      "{'loss': 0.0001, 'learning_rate': 6.599387333592348e-06, 'epoch': 4.5}          \n",
      "{'loss': 0.0001, 'learning_rate': 6.155189589713833e-06, 'epoch': 4.51}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.7261535240771426e-06, 'epoch': 4.53}        \n",
      "{'loss': 0.0001, 'learning_rate': 5.312324358381731e-06, 'epoch': 4.54}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.913745711473782e-06, 'epoch': 4.56}         \n",
      "{'loss': 0.0001, 'learning_rate': 4.530459594748592e-06, 'epoch': 4.58}         \n",
      "{'loss': 0.0, 'learning_rate': 4.162506407722576e-06, 'epoch': 4.59}            \n",
      "{'loss': 0.0001, 'learning_rate': 3.809924933774977e-06, 'epoch': 4.61}         \n",
      "{'loss': 0.0001, 'learning_rate': 3.4727523360598974e-06, 'epoch': 4.62}        \n",
      "{'loss': 0.0001, 'learning_rate': 3.151024153589321e-06, 'epoch': 4.64}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.8447742974871237e-06, 'epoch': 4.66}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.554035047414732e-06, 'epoch': 4.67}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.2788370481687965e-06, 'epoch': 4.69}        \n",
      "{'loss': 0.0001, 'learning_rate': 2.019209306451075e-06, 'epoch': 4.7}          \n",
      "{'loss': 0.0001, 'learning_rate': 1.7751791878110933e-06, 'epoch': 4.72}        \n",
      "{'loss': 0.0001, 'learning_rate': 1.5467724137617043e-06, 'epoch': 4.74}        \n",
      "{'loss': 0.0, 'learning_rate': 1.3340130590679732e-06, 'epoch': 4.75}           \n",
      "{'loss': 0.0001, 'learning_rate': 1.1369235492096397e-06, 'epoch': 4.77}        \n",
      "{'loss': 0.0001, 'learning_rate': 9.555246580173427e-07, 'epoch': 4.78}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.898355054830719e-07, 'epoch': 4.8}          \n",
      "{'loss': 0.0001, 'learning_rate': 6.398735557448297e-07, 'epoch': 4.82}         \n",
      "{'loss': 0.0001, 'learning_rate': 5.056546152458374e-07, 'epoch': 4.83}         \n",
      "{'loss': 0.0001, 'learning_rate': 3.871928310685335e-07, 'epoch': 4.85}         \n",
      "{'loss': 0.0001, 'learning_rate': 2.845006894433843e-07, 'epoch': 4.86}         \n",
      "{'loss': 0.0001, 'learning_rate': 1.975890144328529e-07, 'epoch': 4.88}         \n",
      "{'loss': 0.0001, 'learning_rate': 1.2646696679042833e-07, 'epoch': 4.9}         \n",
      "{'loss': 0.0001, 'learning_rate': 7.114204299511483e-08, 'epoch': 4.91}         \n",
      "{'loss': 0.0001, 'learning_rate': 3.1620074461297106e-08, 'epoch': 4.93}        \n",
      "{'loss': 0.0001, 'learning_rate': 7.90522692403206e-09, 'epoch': 4.94}          \n",
      "{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 4.96}                           \n",
      "{'train_runtime': 1217.7166, 'train_samples_per_second': 4.106, 'train_steps_per_second': 0.255, 'train_loss': 0.005520118217311627, 'epoch': 4.96}\n",
      "100%|█████████████████████████████████████████| 310/310 [20:17<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "!bash finetune/finetune_lora_single_gpu.sh -m /mnt/workspace/.cache/modelscope/qwen/Qwen-1_8B-Chat-Int4 -d /mnt/workspace/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b8c73-d781-4f1d-bcb4-6fdbc1f52896",
   "metadata": {},
   "source": [
    "加载SFT后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4755934b-0f16-40b9-953c-48b81647b291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T02:56:06.422148Z",
     "iopub.status.busy": "2024-02-17T02:56:06.421846Z",
     "iopub.status.idle": "2024-02-17T02:56:09.569660Z",
     "shell.execute_reply": "2024-02-17T02:56:09.569149Z",
     "shell.execute_reply.started": "2024-02-17T02:56:06.422127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    'output_qwen', # path to the output directory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37bad2f1-cf69-4209-bee6-ad09a2dbee2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T02:56:12.737989Z",
     "iopub.status.busy": "2024-02-17T02:56:12.737680Z",
     "iopub.status.idle": "2024-02-17T02:56:21.291815Z",
     "shell.execute_reply": "2024-02-17T02:56:21.291366Z",
     "shell.execute_reply.started": "2024-02-17T02:56:12.737971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:2020年4月16号三亚下雨么？\n",
      "A:{\"city\": \"三亚\", \"date\": \"2020-04-16\"}\n",
      "\n",
      "Q:青岛3-15号天气预报\n",
      "A:{\"city\": \"青岛\", \"date\": \"03-15\"}\n",
      "\n",
      "Q:5月6号下雪么，城市是威海\n",
      "A:{\"city\": \"威海\", \"date\": \"05-06\"}\n",
      "\n",
      "Q:青岛2023年12月30号有雾霾么?\n",
      "A:{\"city\": \"青岛\", \"date\": \"2023-12-30\"}\n",
      "\n",
      "Q:我打算6月1号去北京旅游，请问天气怎么样？\n",
      "A:{\"city\": \"北京\", \"date\": \"06-01\"}\n",
      "\n",
      "Q:你们打算1月3号坐哪一趟航班去上海？\n",
      "A:{\"city\": \"上海\", \"date\": \"01-03\"}\n",
      "\n",
      "Q:小明和小红是8月8号在上海结婚么?\n",
      "A:{\"city\": \"上海\", \"date\": \"08-08\"}\n",
      "\n",
      "Q:一起去东北看冰雕么，大概是1月15号左右，我们3个人一起\n",
      "A:{\"city\": \"东北\", \"date\": \"01-15\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.generation_config.top_p=0 # 只选择概率最高的token\n",
    "\n",
    "Q_list=['2020年4月16号三亚下雨么？','青岛3-15号天气预报','5月6号下雪么，城市是威海','青岛2023年12月30号有雾霾么?','我打算6月1号去北京旅游，请问天气怎么样？','你们打算1月3号坐哪一趟航班去上海？','小明和小红是8月8号在上海结婚么?',\n",
    "        '一起去东北看冰雕么，大概是1月15号左右，我们3个人一起']\n",
    "for Q in Q_list:\n",
    "    prompt=prompt_template%(Q,)\n",
    "    A,hist=model.chat(tokenizer,prompt,history=None)\n",
    "    print('Q:%s\\nA:%s\\n'%(Q,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e02800a6-b379-4f0e-bea2-301ada6e4061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T02:57:53.410677Z",
     "iopub.status.busy": "2024-02-17T02:57:53.410369Z",
     "iopub.status.idle": "2024-02-17T02:57:55.640749Z",
     "shell.execute_reply": "2024-02-17T02:57:55.640265Z",
     "shell.execute_reply.started": "2024-02-17T02:57:53.410658Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 避免在恶劣天气下钓鱼，如雷雨、大风等。\n",
      "2. 遵守当地的法律法规和规定，不要破坏海洋环境。\n",
      "3. 不要携带违禁物品上岸，以免被罚款或扣押证件。\n"
     ]
    }
   ],
   "source": [
    "prompt='青岛海边钓鱼需要特别注意什么？'\n",
    "resp,hist=model.chat(tokenizer,prompt,history=None)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
